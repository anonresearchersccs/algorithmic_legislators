# Algorithmic Legislators: When Do AI Quotas Improve Legislative Performance?

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: Academic](https://img.shields.io/badge/license-Academic-green.svg)](LICENSE)

A rigorous agent-based model (ABM) examining the effects of AI quotas in legislative bodies. This research project analyzes how artificial intelligence parliamentarians, transparency mechanisms, and adaptive party behavior interact to affect system performance, trust, and representation.

**Submitted to Government Information Quarterly (GIQ)**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Findings](#key-findings)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage Guide](#usage-guide)
- [Model Description](#model-description)
- [Output Files](#output-files)
- [Reproducibility](#reproducibility)
- [Citation](#citation)
- [Authors](#authors)
- [License](#license)

---

## ğŸ”¬ Overview

This repository implements a theoretically-grounded agent-based model to examine when and how AI quotas in legislatures improve performance. The model features:

- **Multi-dimensional policy space**: Parties and voters occupy an N-dimensional ideological space
- **Dual party positions**: Parties have both "real" (private) and "declared" (public) positions
- **Human and AI parliamentarians**: Mixed legislature with configurable AI proportion
- **Transparency mechanisms**: Three levels (input, process, output) affecting inconsistency detection
- **Adaptive party behavior**: Parties can adjust positions when inconsistencies are discovered
- **Rigorous metrics**: All outcomes are theoretically grounded (no simulated noise)

### Key Innovation

Unlike previous models, we measure **real outcomes** derived from model dynamics rather than simulated noise. Our metrics for trust, performance, and satisfaction are computed from actual party-voter distances, inconsistencies, legislative efficiency, and position stability.

---

## ğŸ¯ Key Findings

Based on 7 experimental scenarios Ã— 10 replicates Ã— 50 time steps (3,500+ observations):

1. **Baseline Performance**: 0.676 (no AI, no transparency)

2. **Transparency alone harms performance**: 
   - Moderate AI (30%) + Transparency + NO Adaptation: 0.777
   - Change from baseline: +14.8%

3. **Moderate AI with transparency AND adaptation improves performance**:
   - Moderate AI (30%) + Transparency + Adaptation: 0.806
   - Change from baseline: +19.2%
   - **Optimal range**: 20-30% AI quota

4. **High AI quotas show diminishing returns**:
   - High AI (50%) + Transparency + Adaptation: 0.897
   - Change from baseline: +32.6%

5. **Critical mechanism**: Transparency â†’ Inconsistency Detection â†’ Adaptation â†’ Performance
   - Without adaptation, transparency exposes inconsistencies but doesn't fix them
   - With adaptation, parties realign toward their real positions, improving representation

**Policy Implication**: Institutional design matters. AI quotas require complementary transparency and accountability mechanisms to deliver benefits.

---

## ğŸ“ Project Structure

```
CODE/
â”‚
â”œâ”€â”€ Core Model Files
â”‚   â”œâ”€â”€ algorithmic_legislators_SOTA.py      # Main ABM with real metrics
â”‚   â”œâ”€â”€ visualization_analysis_SOTA.py       # Statistical analysis & figures
â”‚   â”œâ”€â”€ sensitivity_analysis_robust.py       # Robustness checks
â”‚   â””â”€â”€ run_complete_analysis_GIQ.py         # Full pipeline runner
â”‚
â”œâ”€â”€ Interactive Notebooks
â”‚   â””â”€â”€ Algorithmic_Legislators_GIQ.ipynb    # Jupyter notebook interface
â”‚
â”œâ”€â”€ Manuscript Files
â”‚   â”œâ”€â”€ manuscript_GIQ.tex                   # LaTeX manuscript
â”‚   â”œâ”€â”€ manuscript_GIQ.pdf                   # Compiled PDF
â”‚   â””â”€â”€ references.bib                       # Bibliography
â”‚
â”œâ”€â”€ Data Outputs (Generated)
â”‚   â”œâ”€â”€ results_GIQ_SOTA.csv                 # Main simulation results
â”‚   â”œâ”€â”€ table1_main_results.csv              # Statistical tests
â”‚   â”œâ”€â”€ summary_statistics_GIQ.csv           # Descriptive stats
â”‚   â”œâ”€â”€ pareto_frontier_GIQ.csv              # Pareto-optimal points
â”‚   â”œâ”€â”€ supp_dense_grid.csv                  # Dense AI quota grid (0-60%)
â”‚   â”œâ”€â”€ supp_do_interventions.csv            # Causal interventions
â”‚   â””â”€â”€ supp_transparency_factorial.csv      # 2Ã—2Ã—2 transparency factorial
â”‚
â”œâ”€â”€ Figures (Generated)
â”‚   â”œâ”€â”€ figure1_tradeoff_GIQ.html            # Performance vs Trust trade-off
â”‚   â”œâ”€â”€ figure2_dynamics_GIQ.html            # Temporal evolution
â”‚   â”œâ”€â”€ figure3_spatial_GIQ.html             # Party position trajectories
â”‚   â”œâ”€â”€ figure4_interaction_GIQ.html         # AI Ã— Transparency interaction
â”‚   â””â”€â”€ figures/*.png                        # PNG versions for manuscript
â”‚
â”œâ”€â”€ Supporting Files
â”‚   â”œâ”€â”€ requirements.txt                     # Python dependencies
â”‚   â”œâ”€â”€ api_key.txt                          # OpenAI API key (optional)
â”‚   â”œâ”€â”€ findings_summary.txt                 # Key results summary
â”‚   â”œâ”€â”€ convert_figures_to_pdf.py            # Figure conversion utility
â”‚   â”œâ”€â”€ prepare_manuscript_figures.py        # Manuscript figure preparation
â”‚   â”œâ”€â”€ empirical_calibration_guide.py       # Calibration documentation
â”‚   â””â”€â”€ test_api_key.py                      # API key testing
â”‚
â””â”€â”€ README.md                                # This file
```

---

## ğŸ”§ Installation

### Requirements

- **Python**: 3.10 or higher
- **Operating System**: Windows, macOS, or Linux
- **RAM**: 4GB minimum (8GB recommended for large grids)

### Setup

1. **Clone or download this repository**

2. **Install dependencies**:

```bash
pip install -r requirements.txt
```

Dependencies include:
- `agentpy==0.1.5` - Agent-based modeling framework
- `numpy==1.26.4` - Numerical computing
- `pandas==2.2.2` - Data manipulation
- `plotly==5.22.0` - Interactive visualizations
- `scikit-learn==1.4.2` - Statistical analysis
- `tqdm==4.66.4` - Progress bars
- `openai>=1.30.0` - LLM integration (optional)

3. **Optional: OpenAI API key** (for online LLM mode)

Create `api_key.txt` with your key:
```
sk-your-api-key-here
```

**Note**: The model runs perfectly in **offline mode** without an API key. The offline policy uses distance-based heuristics that are faster and reproducible.

---

## ğŸš€ Quick Start

### Option 1: Run Complete Analysis (Recommended)

Generate all figures, tables, and statistical tests:

```bash
python run_complete_analysis_GIQ.py
```

This will:
- Run 7 scenarios Ã— 10 replicates Ã— 50 steps
- Generate all publication figures (HTML + PNG)
- Compute statistical tests (ANOVA, t-tests, effect sizes)
- Export tables and summary statistics
- **Estimated time**: 10-15 minutes

### Option 2: Interactive Notebook

```bash
jupyter notebook Algorithmic_Legislators_GIQ.ipynb
```

The notebook provides:
- Step-by-step explanation of the model
- Interactive parameter exploration
- Visualization of individual runs
- Code examples and documentation

### Option 3: Python API

```python
from algorithmic_legislators_SOTA import ExtendedParliamentModel, run_scenarios

# Define scenario
scenario = {
    "num_parties": 4,
    "num_seats": 40,
    "ai_proportion": 0.3,      # 30% AI parliamentarians
    "transparency": 1.0,        # Full transparency
    "num_voters": 100,
    "dimension": 3,             # 3 policy dimensions
    "adapt_threshold": 1.0,
    "adapt_rate": 0.2
}

# Run simulation
df = run_scenarios(
    scenarios=[scenario],
    steps_per_run=50,
    runs_per_scenario=10,
    seed=42,
    out_csv="my_results.csv"
)

# Analyze results
final_step = df[df['step'] == 50]
print(f"Mean performance: {final_step['system_performance'].mean():.3f}")
print(f"Mean trust: {final_step['trust'].mean():.3f}")
```

---

## ğŸ“– Usage Guide

### Main Analyses

#### 1. **Core Experimental Scenarios**

```bash
python run_complete_analysis_GIQ.py
```

Generates: `results_GIQ_SOTA.csv`, `table1_main_results.csv`, Figures 1-4

#### 2. **Dense AI Quota Grid** (Supplementary Material)

Test performance across fine-grained AI quotas (0% to 60%, step 0.05):

```bash
python run_complete_analysis_GIQ.py --supp-dense
python run_complete_analysis_GIQ.py --supp-dense-analyze
```

Generates: `supp_dense_grid.csv` with quadratic fit and bootstrap confidence intervals

#### 3. **Causal Interventions** (do-calculus)

Test robustness with blocked adaptation and exogenous shocks:

```bash
python run_complete_analysis_GIQ.py --supp-do
```

Generates: `supp_do_interventions.csv`

#### 4. **Transparency Factorial** (2Ã—2Ã—2 design)

Decompose transparency into input/process/output components:

```bash
python run_complete_analysis_GIQ.py --supp-factorial
```

Generates: `supp_transparency_factorial.csv`

#### 5. **Comprehensive Sensitivity Analysis**

Test robustness across parameter variations:

```python
from sensitivity_analysis_robust import run_comprehensive_sensitivity

run_comprehensive_sensitivity(
    out_dir="sensitivity_results",
    quick_mode=False  # Set True for faster test run
)
```

Tests variations in:
- Number of parties (3-6)
- Policy dimensions (2-5)
- Adaptation rates (0.1-0.4)
- Voter tolerance (0.1-0.4)
- Metric weights

### Visualization

Create custom figures:

```python
from visualization_analysis_SOTA import (
    plot_tradeoff_analysis,
    plot_temporal_dynamics,
    plot_interaction_effects
)
import pandas as pd

df = pd.read_csv("results_GIQ_SOTA.csv")

# Trade-off plot
plot_tradeoff_analysis(
    df, 
    x_metric='system_performance',
    y_metric='trust',
    out_html='my_tradeoff.html'
)

# Time series
plot_temporal_dynamics(
    df,
    scenarios_to_plot=[0, 2, 5, 6],
    metrics=['trust', 'system_performance']
)
```

---

## ğŸ§® Model Description

### Agents

1. **Parties** (N=4)
   - Real position: `r_p âˆˆ [-1,1]^d` (true ideology)
   - Declared position: `d_p âˆˆ [-1,1]^d` (public stance)
   - Tactical position: `t_p = d_p + noise` (ad-hoc deviations)
   - Discovered inconsistency: `I_p â‰¥ 0` (accumulated penalty)

2. **Voters** (N=100)
   - Ideology: `v_i âˆˆ [-1,1]^d`
   - Dimension weights: `w_i âˆˆ Î”^d` (saliency)
   - Evaluation function: `U(v,p) = -||v - d_p||_w - Î±Â·I_p`

3. **Parliamentarians** (N=40)
   - **Human**: Follow party line, vote based on `||policy - d_p||`
   - **AI**: Use LLM (online) or distance heuristic (offline)
   - Mixed composition: AI proportion Ï âˆˆ [0,1]

### Mechanisms

#### Transparency (T âˆˆ [0,1])

Three components:
- **Input transparency** (T_in): Observability of inputs
- **Process transparency** (T_proc): Observability of deliberation
  - Drives inconsistency discovery: `Î”I_p = T_proc Â· Î³ Â· ||d_p - r_p||`
- **Output transparency** (T_out): Observability of outputs

#### Adaptation

When `I_p > threshold`:
```
d_p â† d_p + Î± Â· (r_p - d_p)
I_p â† 0.7 Â· I_p
```

Parties realign declared positions toward real positions.

### Metrics (Theoretically Grounded)

#### 1. Trust [0,1]
```
Trust = 0.35Â·Consistency + 0.35Â·Transparency_Effectiveness + 0.30Â·Alignment

Consistency = 1/(1 + mean(||d_p - r_p||))
Transparency_Effectiveness = 1/(1 + T_procÂ·Î³Â·Inconsistency)
Alignment = 1/(1 + mean_voter_distance)
```

#### 2. System Performance [0,1]
```
Performance = 0.40Â·Efficiency + 0.40Â·Representativity + 0.20Â·Stability

Efficiency = bills_passed / total_bills
Representativity = 1 - (mean_voter_distance / normalization)
Stability = 1/(1 + mean_party_movement)
```

#### 3. Voter Satisfaction [0,1]
```
Satisfaction = mean(normalized_best_evaluation)
```

All metrics are computed from **actual model dynamics**â€”no random noise added.

---

## ğŸ“Š Output Files

### Main Data Files

| File | Description | Rows | Key Columns |
|------|-------------|------|-------------|
| `results_GIQ_SOTA.csv` | Main simulation results | 3,500 | step, trust, system_performance, ai_proportion, transparency |
| `table1_main_results.csv` | Statistical tests | 7 scenarios | mean, sd, p-value, cohen_d, CI |
| `summary_statistics_GIQ.csv` | Descriptive stats | 7 scenarios | mean, median, std, min, max |
| `pareto_frontier_GIQ.csv` | Pareto-optimal configs | ~20 | performance, trust, ai_proportion |

### Supplementary Data

| File | Description | Purpose |
|------|-------------|---------|
| `supp_dense_grid.csv` | Dense AI quota grid (0-60%, Î”=5%) | Optimal quota estimation |
| `supp_do_interventions.csv` | Causal interventions | Robustness to shocks |
| `supp_transparency_factorial.csv` | 2Ã—2Ã—2 factorial design | Transparency decomposition |

### Figures

All figures available in both HTML (interactive) and PNG (publication) formats:

1. **Figure 1**: Performance vs Trust trade-off (scatterplot with convex hull)
2. **Figure 2**: Temporal dynamics (4-panel time series)
3. **Figure 3**: Spatial trajectories (3D party position evolution)
4. **Figure 4**: AI Ã— Transparency interaction (line plot with CI)

---

## ğŸ”’ Reproducibility

### Seeds and Determinism

- All runs use explicit random seeds: `seed + scenario_id * 1000 + replicate`
- Seeds are recorded in output files
- Offline mode is fully deterministic

### Reproduce Published Results

```bash
# Main results
python run_complete_analysis_GIQ.py

# Supplementary analyses
python run_complete_analysis_GIQ.py --supp-dense
python run_complete_analysis_GIQ.py --supp-do
python run_complete_analysis_GIQ.py --supp-factorial
```

### Environment

Use exact versions from `requirements.txt`:

```bash
pip install -r requirements.txt --no-cache-dir
```

**Python version tested**: 3.10.13, 3.11.5, 3.12.1

---

## ğŸ“š Citation

If you use this code or model, please cite:

```bibtex
@article{pablo-marti2025algorithmic,
  title={When Do AI Quotas Improve Legislative Performance? 
         Experimental Evidence from Agent-Based Modeling},
  author={Pablo-Mart{\'i}, Federico and Mir Fern{\'a}ndez, Carlos 
          and Olmeda Martos, Ignacio},
  journal={Government Information Quarterly},
  year={2025},
  note={Under review}
}
```

---

## ğŸ‘¥ Authors

- **Federico Pablo-MartÃ­** - Universidad de AlcalÃ¡
- **Carlos Mir FernÃ¡ndez** - Universidad de AlcalÃ¡  
- **Ignacio Olmeda Martos** - [Affiliation]

### Correspondence

For questions or collaboration:
- Email: federico.pablo@uah.es
- Repository: [GitHub URL]

---

## ğŸ“„ License

This code is provided for **academic and research purposes only**.

- âœ… You may use, modify, and share for non-commercial research
- âœ… Please cite the manuscript when using this code
- âŒ Commercial use requires explicit permission from authors

See `LICENSE` file for full terms.

---

## ğŸ™ Acknowledgments

This research was supported by [funding information].

Special thanks to:
- Agent-based modeling community
- Reviewers at Government Information Quarterly
- Open-source Python ecosystem (NumPy, Pandas, Plotly, AgentPy)

---

## ğŸ“ Changelog

### Version 1.0 (2025-01-XX) - GIQ Submission
- Rigorous metrics (replaced simulated noise with real calculations)
- Complete statistical analysis pipeline
- Supplementary robustness checks
- Publication-ready figures
- Comprehensive documentation

---

## ğŸ› Issues and Contributions

Found a bug? Have a suggestion? Please open an issue on GitHub or contact the authors.

**Note**: This is research code accompanying a manuscript. We may not accept major feature requests until after publication.

---

**Last updated**: October 2025  
**Status**: Under review at Government Information Quarterly
